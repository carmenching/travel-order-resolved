{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import spacy\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.svm import SVC\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate datasets\n",
    "1. Sentences that are itineraries for training -- Here we generate only sentences that are identifical and has three different structures\n",
    "> Je veux aller de depart à destination\n",
    "<br>\n",
    "> Trajet de depart à destination\n",
    "<br>\n",
    "> Aller-retour de depart à destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences = []\n",
    "test_sentences = []\n",
    "train_labels = []\n",
    "test_labels = []\n",
    "\n",
    "with open('stops.txt', encoding='UTF-8') as file_stops:\n",
    "            data_stops = csv.reader(file_stops, delimiter=',')\n",
    "            next(data_stops)\n",
    "            list_stops=[]\n",
    "            for row in data_stops:\n",
    "                # stop_name = row[1].strip().replace(' ', '_')\n",
    "                # list_stops.append(stop_name)\n",
    "                list_stops.append(row[1].strip())\n",
    "\n",
    "        # Get all the cities of France \n",
    "with open('commune_2022.csv', encoding='ISO-8859-1') as file_cities : \n",
    "    data_cities = csv.reader(file_cities, delimiter=',')\n",
    "    next(data_cities)\n",
    "    \n",
    "    list_cities=[]\n",
    "    for row in data_cities:\n",
    "        # city_name = row[6].strip().replace(' ', '_')\n",
    "        # list_cities.append(city_name)\n",
    "        list_cities.append(row[6].strip())\n",
    "\n",
    "i = 0\n",
    "for x in range(0, 100):\n",
    "    if x<= 30:\n",
    "        if i == 0:\n",
    "            sentence = 'Trajet de {} à {}'.format(list_cities[random.randint(0, len(list_cities)-1)], list_cities[random.randint(0, len(list_cities)-1)+1])\n",
    "            i = i+1\n",
    "        elif i == 1:\n",
    "            sentence = 'Je veux aller de {} à {}'.format(list_cities[random.randint(0, len(list_cities)-1)], list_cities[random.randint(0, len(list_cities)-1)+1])\n",
    "            i = i+1\n",
    "        elif i == 2:\n",
    "            sentence = 'Aller-retour de {} à {}'.format(list_cities[random.randint(0, len(list_cities)-1)], list_cities[random.randint(0, len(list_cities)-1)+1])\n",
    "            i = i+1\n",
    "        elif i == 3:\n",
    "            sentence = 'Je veux aller de {} à {}'.format(list_stops[random.randint(0,len(list_stops)-1)], list_stops[random.randint(0, len(list_stops)-1)+1])\n",
    "            i = i+1\n",
    "        elif i == 4:\n",
    "            sentence = 'Trajet de {} à {}'.format(list_stops[random.randint(0,len(list_stops)-1)], list_stops[random.randint(0, len(list_stops)-1)+1])\n",
    "            i = i+1\n",
    "        else:\n",
    "            sentence = 'Aller-retour de {} à {}'.format(list_stops[random.randint(0,len(list_stops)-1)], list_stops[random.randint(0, len(list_stops)-1)+1])\n",
    "            i = 0\n",
    "\n",
    "        test_sentences.append(sentence.lower())\n",
    "        test_labels.append(1)\n",
    "\n",
    "    else: \n",
    "        if i == 0:\n",
    "            sentence = 'Je veux aller de depart à destination'\n",
    "            i = i+1\n",
    "        elif i == 1:\n",
    "            sentence = 'Trajet de depart à destination'\n",
    "            i = i+1\n",
    "        else:\n",
    "            sentence = 'Aller-retour de depart à destination'\n",
    "            i = 0\n",
    "\n",
    "        train_sentences.append(sentence.lower())\n",
    "        train_labels.append(1)\n",
    "    \n",
    "## Add to the same array, the sentences that are not itineraries\n",
    "with open('random_not_itinerary.csv', encoding=\"UTF-8\") as file_non_itinerary:\n",
    "    data_not_itinerary = csv.reader(file_non_itinerary, delimiter=',')\n",
    "    i = 0\n",
    "    for row in data_not_itinerary:\n",
    "        i=i+1\n",
    "        if i>= 50:\n",
    "            test_sentences.append(row[0].lower())\n",
    "            test_labels.append(0)\n",
    "        else:\n",
    "            train_sentences.append(row[0].lower())\n",
    "            train_labels.append(0)\n",
    "            \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Review dataset generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------\n",
      "Training dataset 118\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "Testing dataset: 86\n",
      "---------------------------------------------------------\n",
      "['trajet de pleuville à memont', 'je veux aller de beaulieu à roquettes', 'aller-retour de bastelica à reviers', 'je veux aller de gare de baisieux à lugny', 'trajet de gare de colmar à gare de montferrand-thoraise', 'aller-retour de gare de onzain-chaumont-/-l à farébersviller (cité)', 'trajet de paris à aixe sur vienne', 'je veux aller de fignevelle à dessenheim', 'aller-retour de chaouilley à meolans revel', 'je veux aller de seilhan-le-bazert à gare de vic-mireval', 'trajet de gare de bréval à gare de crouy', 'aller-retour de marimont-lès-bénestroff à gare de seurre', 'trajet de fontaine la louvet à estaing', 'je veux aller de larressingle à cestas', 'aller-retour de argut dessus à lugy', 'je veux aller de gare de anizy-pinon à gare de st-blaise-roche-poutay', 'trajet de gare de ker lann à gare de cattenières', 'aller-retour de gare de veauche st galmier à gare de val-de-reuil', 'trajet de moriville à colombe', 'je veux aller de reventin vaugris à beauval en caux', 'aller-retour de fontenoy le chateau à savigneux', 'je veux aller de gare de st-aubin-st-luperce à diebling-forestière', 'trajet de gare de sept-saulx à st-eble', 'aller-retour de gare de valence-ville à bricon(la poste)', 'trajet de coise saint jean pied gauthier à saint marc sur couesnon', 'je veux aller de coulonvillers à faverelles', 'aller-retour de maisoncelles à claret', 'je veux aller de gare de reichshoffen-ville à gare de sermizelles-vézelay', 'trajet de gare de ligugé à gare de maromme', 'aller-retour de verneuil à gare de lesparre', 'trajet de grisy suisnes à neuvelle les scey', 'le voyage durera 3 heures de 8 heures à 11 heures.', \"je suis allé de la maison à l'école à pied.\", \"j'ai reçu un cadeau de ma mère à mon anniversaire.\", 'la région des pays de la loire est réputée pour ses vignobles et ses châteaux.', 'la gare de lille europe est un important hub ferroviaire en france.', 'la ville de toulouse est connue pour son architecture et son patrimoine historique.', 'la région de rhône-alpes est célèbre pour ses montagnes, notamment les alpes.', \"la gare de montparnasse est un important point de passage pour les trains vers l'ouest de la france.\", 'la ville de bordeaux est célèbre pour son vin et sa gastronomie.', 'la région de nord-pas-de-calais est célèbre pour ses ports et ses industries.', \"la gare de nantes est un important hub ferroviaire dans l'ouest de la france.\", 'la ville de lille est un important centre commercial et économique en france.', 'la région de lorraine est célèbre pour ses forêts et ses montagnes.', \"la gare de brest est un important point de passage pour les trains vers l'ouest de la france.\", 'la ville de nice est célèbre pour son climat agréable et sa promenade des anglais.', 'la région de champagne-ardenne est célèbre pour ses vignobles et ses champagnes.', \"la gare de strasbourg est un important hub ferroviaire dans l'est de la france.\", 'la ville de lyon est célèbre pour sa gastronomie et son patrimoine historique.', 'la région de franche-comté est célèbre pour ses vignobles et ses fromages.', \"la gare de rennes est un important point de passage pour les trains vers l'o\", 'je suis en train de visiter la ville de lyon.', 'mon prochain voyage sera à la gare de marseille.', \"j'ai passé les vacances d'été dans la région de la côte d'azur.\", 'la ville de paris est connue pour ses monuments célèbres.', 'la gare de lyon est un point de passage important pour les voyageurs.', \"j'ai découvert de magnifiques paysages dans la région de provence.\", 'la ville de bordeaux est réputée pour son vin de qualité.', 'la gare de lille est une étape incontournable pour les voyageurs en provenance du nord de la france.', \"j'ai passé un week-end inoubliable dans la région du languedoc-roussillon.\", \"la ville de toulouse est une destination idéale pour les amoureux de l'histoire et de la culture.\", 'la gare de montpellier est un point de départ idéal pour explorer la région du sud de la france.', \"j'ai découvert de nombreux trésors cachés dans la région de normandie.\", \"la ville de nantes est une destination idéale pour les amateurs d'art et de culture.\", 'la gare de rennes est un passage obligé pour les voyageurs en provenance de la bretagne.', \"j'ai passé un séjour inoubliable dans la région de la corse.\", 'la ville de lille est une destination idéale pour les amateurs de shopping et de gastronomie.', 'la gare de strasbourg est un point de départ idéal pour explorer les régions du nord-est de la france.', \"j'ai découvert de nombreux joyaux architecturaux dans la région de champagne-ardenne.\", 'la ville de nice est une destination de rêve pour les amoureux de la nature et de la mer.', 'la gare de bordeaux est un point de passage incontournable pour les voyageurs en provenance du sud-ouest de la france.', \"j'étais chez mes parent de 13 à 17 heures aujourd'hui.\", 'mon ami vient de france mais il habite à londres maintenant.', \"le livre que je lis est de l'auteur célèbre j.k. rowling.\", 'je dois rendre mon travail à mon professeur demain.', \"j'ai reçu une lettre de mon grand-père à noël.\", 'je vais acheter des fruits et des légumes au marché.', \"j'ai perdu mon livre de français quelque part dans la maison.\", 'je vais de la bibliothèque à la maison en bus.', 'je dois rendre mon travail de sciences à mon professeur lundi prochain.', 'mon chien aime se promener dans les bois et dans les champs.', \"j'ai acheté un livre de poésie à la bibliothèque.\", 'je vais de la salle de classe à la cour de récréation pendant la pause déjeuner.', \"mon amie vient de l'italie mais elle habite à madrid depuis un an.\", 'amènes-moi à toulouse.', \"j'ai resté à paris.\"]\n"
     ]
    }
   ],
   "source": [
    "print(\"---------------------------------------------------------\")\n",
    "print(f\"Training dataset {len(train_sentences)}\")\n",
    "print(\"---------------------------------------------------------\")\n",
    "# print(train_sentences)\n",
    "\n",
    "print(\"---------------------------------------------------------\")\n",
    "print(f\"Testing dataset: {len(test_sentences)}\")\n",
    "print(\"---------------------------------------------------------\")\n",
    "print(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "la région de nord-pas-de-calais est célèbre pour ses ports et ses industries.\n",
      "0\n",
      "trajet de pleuville à memont\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(shuffled_test_sentences[0])\n",
    "print(shuffled_test_labels[0])\n",
    "print(test_sentences[0])\n",
    "print(test_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_test_sentences = test_sentences.copy()\n",
    "random.shuffle(shuffled_test_sentences)\n",
    "\n",
    "shuffled_test_labels = []\n",
    "for sentence in shuffled_test_sentences:\n",
    "    shuffled_test_labels.append(test_labels[test_sentences.index(sentence)])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model\n",
    "Launch the training with instructions for SVM to look out for features based on the key words that was preprocessed earlier.\n",
    "As the generated dataset revolve around sentences with similar structures and as we include the possible ways of asking for directions in actual real-life behaviour, we have determined to train our SVM with 4 specific set of keywords. \n",
    "(\"de depart\", \"aller-retour\", \"trajet de\", \"à destination\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create feature vector for each sentence\n",
    "features = np.array([[len(sentence), sentence.count(\"de depart\"), sentence.count(\"aller-retour\"), sentence.count(\"Trajet de\"), sentence.count(\"à destination\")] for sentence in train_sentences])\n",
    "\n",
    "# create labels for each sentence\n",
    "labels = np.array(train_labels) # 0 = not itinerary, 1 = itinerary\n",
    "\n",
    "# create and train the SVM model\n",
    "model = SVC(kernel=\"linear\")\n",
    "model.fit(features, labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-process datasets\n",
    "We will label those destinations at best before feeding it to our model for training and prediction by detecting if therer are keywords like \"aller\", \"retour\", \"de\" and \"à\" which hints that the next words could concern a destination or a transiting point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp = spacy.load(\"fr_core_news_lg\")\n",
    "# test = nlp(\"trajet de gare_de_colmar_st_joseph à gare_de_chatelaillon_plage\")\n",
    "# for token in test:\n",
    "#     print(f\"{token.text}:{token.pos_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_frequent_words = [\"aller\", \"retour\", \"à\", \"trajet\"]\n",
    "pos_to_replace = [\"NOUN\", \"PROPN\"]\n",
    "def labelling_keywords(sentences):\n",
    "    filtered_sentences = []\n",
    "    nlp = spacy.load(\"fr_core_news_lg\")\n",
    "    corpus = nlp.pipe(sentences)\n",
    "    for idx, doc in enumerate(corpus):\n",
    "        sentence = \"\"\n",
    "        doc_ents = OrderedDict()\n",
    "        # for ent in doc.ents:\n",
    "        #     doc_key = ent.text\n",
    "        #     # print(f\"{doc_key}:{ent.label_}\")\n",
    "        \n",
    "        for token in doc:\n",
    "            if token.text in nlp.vocab:\n",
    "                # print(f\"{idx} - {token.text}: {token.pos_}\")\n",
    "                if (token.text.lower() not in list_of_frequent_words) :\n",
    "                    if token.text.lower() == \"de\" and doc[token.i-1].text.lower().strip() != \"gare\" and not \"depart\" in sentence:\n",
    "                        sentence += f\" {token.text.lower().strip()} \"\n",
    "                        if doc[token.i+1].pos_ in pos_to_replace:\n",
    "                            sentence += \"depart\"\n",
    "                        else:\n",
    "                            sentence += f' {token.text.lower().strip()}'\n",
    "                    elif doc[token.i-1].text.lower().strip() == \"à\" and token.pos_ in pos_to_replace:\n",
    "                        sentence += \" destination\"\n",
    "                    elif (doc[token.i-1].text.lower().strip() == \"de\" and doc[token.i-2].text.lower().strip() != \"gare\") :\n",
    "                        sentence += \"\"\n",
    "                    elif (doc[token.i-1].text.lower().strip() == \"-\"):\n",
    "                        sentence += \"\"\n",
    "                    elif token.text.lower().strip() == \"-\":\n",
    "                        sentence += \"\"\n",
    "                    elif (token.text.lower() == \"de\" and doc[token.i-1].text.lower().strip() == \"gare\"):\n",
    "                        sentence += \"\"\n",
    "                    else:\n",
    "                        sentence += f' {token.text.lower().strip()}'\n",
    "                else:\n",
    "                    sentence += f' {token.text.lower().strip()}'\n",
    "        # print(words_filtered)\n",
    "\n",
    "        \n",
    "        filtered_sentences.append(sentence)\n",
    "    return filtered_sentences\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we will test it with the test dataset underwent the same preprocessing. We will have SVM to look out for the same features as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' la région de depart est célèbre pour ses ports et ses industries .',\n",
       " ' aller retour de depart onzain à farébersviller ( cité )',\n",
       " ' mon amie vient de  de italie mais elle habite à destination depuis un an .',\n",
       " ' la ville de depart est un important centre commercial et économique en france .',\n",
       " ' je suis en train de  de la ville de depart .',\n",
       " ' je dois rendre mon travail à mon professeur demain .',\n",
       " ' le livre que je lis est de  de auteur célèbre j.k . rowling .',\n",
       " ' aller retour de depart le chateau à savigneux',\n",
       " ' la région de depart est célèbre pour ses forêts et ses montagnes .',\n",
       " \" j' ai reçu une lettre de  de grand-père à destination .\",\n",
       " ' trajet de depart colmar à destination montferrand',\n",
       " ' la ville de depart est connue pour ses monuments célèbres .',\n",
       " ' aller retour de depart valence à bricon(la poste )',\n",
       " ' mon prochain voyage sera à la gare marseille .',\n",
       " ' aller retour de depart à destination lesparre',\n",
       " ' je veux aller de depart à destination',\n",
       " ' la gare rennes est un passage obligé pour les voyageurs en provenance de  de bretagne .',\n",
       " ' je vais de  de bibliothèque à la maison en bus .',\n",
       " ' mon chien aime se promener dans les bois et dans les champs .',\n",
       " ' la région de depart est célèbre pour ses montagnes , notamment les alpes .',\n",
       " ' trajet de depart ligugé à destination maromme',\n",
       " \" la ville de  de est une destination idéale pour les amateurs d' art et de depart .\",\n",
       " ' la ville de depart est une destination idéale pour les amateurs de et de .',\n",
       " \" la gare nantes est un important hub ferroviaire dans l' ouest de  de france .\",\n",
       " ' trajet de depart ker lann à destination cattenières',\n",
       " ' je veux aller de depart anizy à destination st',\n",
       " \" la gare rennes est un important point de depart pour les trains vers l' o\",\n",
       " ' la ville de depart est connue pour son architecture et son patrimoine historique .',\n",
       " \" j' étais chez mes parent de  de à 17 heures aujourd'hui .\",\n",
       " ' trajet de depart bréval à destination crouy',\n",
       " ' la ville de depart est une destination de pour les amoureux de nature et de mer .',\n",
       " ' la ville de depart est célèbre pour sa gastronomie et son patrimoine historique .',\n",
       " \" j' ai découvert de  de paysages dans la région de depart .\",\n",
       " ' je vais acheter des fruits et des légumes au marché .',\n",
       " ' trajet de depart à destination',\n",
       " ' trajet de depart à destination sur vienne',\n",
       " ' la ville de depart est célèbre pour son vin et sa gastronomie .',\n",
       " ' aller retour de depart à destination',\n",
       " ' je veux aller de depart à cestas',\n",
       " \" j' ai resté à destination .\",\n",
       " ' aller retour de depart dessus à destination',\n",
       " ' la gare lille europe est un important hub ferroviaire en france .',\n",
       " ' la gare lille est une étape incontournable pour les voyageurs en provenance du nord de  de france .',\n",
       " ' aller retour de depart veauche st galmier à destination val-de-reuil',\n",
       " ' trajet de depart saint jean pied gauthier à destination marc sur couesnon',\n",
       " ' la région de depart est célèbre pour ses vignobles et ses fromages .',\n",
       " \" j' ai reçu un cadeau de  de mère à mon anniversaire .\",\n",
       " ' aller retour de depart à destination revel',\n",
       " ' trajet de depart la louvet à destination',\n",
       " \" la gare montparnasse est un important point de depart pour les trains vers l' ouest de france .\",\n",
       " ' aller retour de depart à destination seurre',\n",
       " ' je veux aller de  de à faverelles',\n",
       " ' la ville de depart est célèbre pour son climat agréable et sa promenade des anglais .',\n",
       " \" la gare strasbourg est un important hub ferroviaire dans l' est de  de france .\",\n",
       " ' je veux aller de depart baisieux à destination',\n",
       " ' la gare bordeaux est un point de depart incontournable pour les voyageurs en provenance du sud-ouest de france .',\n",
       " ' la région de depart est célèbre pour ses vignobles et ses champagnes .',\n",
       " ' la gare strasbourg est un point de depart idéal pour explorer les régions du nord-est de france .',\n",
       " ' la gare montpellier est un point de depart idéal pour explorer la région du sud de france .',\n",
       " ' trajet de depart sept à destination',\n",
       " \" j' ai perdu mon livre de depart quelque part dans la maison .\",\n",
       " ' la ville de depart est une destination idéale pour les amoureux de histoire et de culture .',\n",
       " \" j' ai découvert de  de trésors cachés dans la région de depart .\",\n",
       " ' aller retour de  de à destination',\n",
       " ' je dois rendre mon travail de depart à mon professeur lundi prochain .',\n",
       " ' le voyage durera 3 heures de  de heures à 11 heures .',\n",
       " ' je vais de  de salle de depart à la cour de pendant la pause déjeuner .',\n",
       " ' trajet de depart suisnes à destination les scey',\n",
       " ' je veux aller de depart st à destination',\n",
       " ' je veux aller de depart vaugris à destination en caux',\n",
       " ' amènes -moi à destination .',\n",
       " ' mon ami vient de depart mais il habite à destination maintenant .',\n",
       " \" j' ai passé un week inoubliable dans la région du languedoc .\",\n",
       " \" la gare brest est un important point de depart pour les trains vers l' ouest de france .\",\n",
       " \" j' ai passé les vacances d' été dans la région de  de côte d' azur .\",\n",
       " ' trajet de depart à destination',\n",
       " ' la ville de depart est réputée pour son vin de .',\n",
       " ' je veux aller de depart reichshoffen à destination sermizelles',\n",
       " \" je suis allé de  de maison à l' école à destination .\",\n",
       " \" j' ai acheté un livre de depart à la bibliothèque .\",\n",
       " \" j' ai passé un séjour inoubliable dans la région de  de corse .\",\n",
       " \" j' ai découvert de  de joyaux architecturaux dans la région de depart .\",\n",
       " ' je veux aller de depart à destination',\n",
       " ' la région des pays de  de loire est réputée pour ses vignobles et ses châteaux .',\n",
       " ' je veux aller de depart à destination vic',\n",
       " ' la gare lyon est un point de depart important pour les voyageurs .']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentences_filtered = labelling_keywords(shuffled_test_sentences)\n",
    "test_sentences_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the model on a new sentence\n",
    "results = []\n",
    "results_label = []\n",
    "\n",
    "for test in test_sentences_filtered:\n",
    "  test_features = np.array([[len(test), test.count(\"de depart\"),  test.count(\"aller-retour\"), test.count(\"trajet de\"), test.count(\"à destination\")]])\n",
    "  prediction = model.predict(test_features)\n",
    "  if prediction[0] == 0:\n",
    "    results.append(\"The sentence is not an itinerary.\")\n",
    "  else:\n",
    "    results.append(\"The sentence is an itinerary.\")\n",
    "  results_label.append(prediction[0])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results of testing\n",
    "Here we will present the descrepancies in terms of results between the correct labels and the guessed labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model's accuracy : 0.9186046511627907\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(shuffled_test_labels, results_label)\n",
    "print(f\"model's accuracy : {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrong answers: 7\n",
      "total sentences: 86\n",
      "sentences guessed wrongly:\n",
      "-----------------------------\n",
      "aller-retour de gare de onzain-chaumont-/-l à farébersviller (cité) | was guessed as 0 and test label is 1\n",
      "aller-retour de fontenoy le chateau à savigneux | was guessed as 0 and test label is 1\n",
      "aller-retour de gare de valence-ville à bricon(la poste) | was guessed as 0 and test label is 1\n",
      "j'ai resté à paris. | was guessed as 1 and test label is 0\n",
      "je veux aller de coulonvillers à faverelles | was guessed as 0 and test label is 1\n",
      "amènes-moi à toulouse. | was guessed as 1 and test label is 0\n",
      "mon ami vient de france mais il habite à londres maintenant. | was guessed as 1 and test label is 0\n"
     ]
    }
   ],
   "source": [
    "wrong_answers = 0\n",
    "sentences_guessed_wrongly = []\n",
    "wrong_labels = []\n",
    "for index, result in enumerate(results_label):\n",
    "    if result != shuffled_test_labels[index]:\n",
    "        # print(f\"result {result} | shuffled {shuffled_test_labels[index]}\")\n",
    "        wrong_answers=wrong_answers+1\n",
    "        sentences_guessed_wrongly.append(shuffled_test_sentences[index])\n",
    "        wrong_labels.append(result)\n",
    "        # print(f\"answer : {test_labels[index]}, predicted as {result}\")\n",
    "print(f\"wrong answers: {wrong_answers}\")\n",
    "print(f\"total sentences: {len(shuffled_test_labels)}\")\n",
    "print(\"sentences guessed wrongly:\")\n",
    "print(\"-----------------------------\")\n",
    "for index, sentence in enumerate(sentences_guessed_wrongly):\n",
    "    print(f\"{sentence} | was guessed as {wrong_labels[index]} and test label is {shuffled_test_labels[shuffled_test_sentences.index(sentence)]}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing with single spontaneous sentence\n",
    "We provide an impromptu sentence for the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence tested: ['à destination.']\n",
      "The sentence should not be an itinerary\n",
      "guessed as: {is an itinerary}\n"
     ]
    }
   ],
   "source": [
    "single_test_sentence = [\"à destination.\"]\n",
    "single_test_sentence_filtered = labelling_keywords(single_test_sentence)\n",
    "single_test_labels = [0]\n",
    "results_label = []\n",
    "for test in single_test_sentence_filtered:\n",
    "  test_features = np.array([[len(test), test.count(\"de depart\"), test.count(\"aller-retour\"), test.count(\"Trajet de\"), test.count(\"à destination\")]])\n",
    "  prediction = model.predict(test_features)\n",
    "  if prediction[0] == 0:\n",
    "    results.append(\"The sentence is not an itinerary.\")\n",
    "  else:\n",
    "    results.append(\"The sentence is an itinerary.\")\n",
    "  results_label.append(prediction[0])\n",
    "\n",
    "print(f\"sentence tested: {single_test_sentence}\")\n",
    "print(f'The sentence should {\"not\" if single_test_labels[0] == 0 else \"\"} be an itinerary')\n",
    "for result in results_label:\n",
    "  print(f'guessed as: {\"{is an itinerary}\" if result == 1 else \"{not an itinerary}\"}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment with voice recognition component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Je veux aller de Albi à Marseille.']\n",
      "guessed as: {is an itinerary}\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "with open('record_16-10-05.txt', encoding='UTF-8') as file_record:\n",
    "  data.append(file_record.readline().strip())\n",
    "print(data)\n",
    "single_test_sentences=data\n",
    "single_test_sentence_filtered = labelling_keywords(single_test_sentence)\n",
    "results_label = []\n",
    "for test in single_test_sentence_filtered:\n",
    "  test_features = np.array([[len(test), test.count(\"de depart\"), test.count(\"aller-retour\"), test.count(\"Trajet de\"), test.count(\"à destination\")]])\n",
    "  prediction = model.predict(test_features)\n",
    "  if prediction[0] == 0:\n",
    "    results.append(\"The sentence is not an itinerary.\")\n",
    "  else:\n",
    "    results.append(\"The sentence is an itinerary.\")\n",
    "  results_label.append(prediction[0])\n",
    "\n",
    "for result in results_label:\n",
    "  print(f'guessed as: {\"{is an itinerary}\" if result == 1 else \"{not an itinerary}\"}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the model to a file\n",
    "with open('svm_model.pkl', 'wb') as f:\n",
    "  pickle.dump(model, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ---- testing with spacy -------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text: Gaillac-12-N88 | pos: PROPN\n",
      "text: / | pos: ADP\n",
      "text: D95 | pos: SPACE\n"
     ]
    }
   ],
   "source": [
    "# departure = \"\"\n",
    "# print(\"empty string\") if not departure else print(\"not empty\")\n",
    "import spacy\n",
    "nlp = spacy.load(\"fr_core_news_lg\")\n",
    "spacy.explain(\"SPACE\")\n",
    "test = nlp(\"Gaillac-12-N88/D95\")\n",
    "for token in test:\n",
    "    print(f\"text: {token.text} | pos: {token.pos_}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 | packaged by conda-forge | (main, Nov 24 2022, 14:07:00) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6146b1389f26bce5dd41fb48b3cc31714c8f490cceff5b6154503e4a63fcf512"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
